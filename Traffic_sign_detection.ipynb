{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'Generate_tfrecord_fromCSV.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WORKSPACE_PATH': 'TF_Sign_Detection/workspace',\n",
       " 'SCRIPTS_PATH': 'TF_Sign_Detection/scripts',\n",
       " 'APIMODEL_PATH': 'TF_Sign_Detection/models',\n",
       " 'ANNOTATION_PATH': 'TF_Sign_Detection/workspace/annotations',\n",
       " 'IMAGE_PATH': 'TF_Sign_Detection/workspace/images',\n",
       " 'MODEL_PATH': 'TF_Sign_Detection/workspace/models',\n",
       " 'PRETRAINED_MODEL_PATH': 'TF_Sign_Detection/workspace/pre-trained-models',\n",
       " 'CHECKPOINT_PATH': 'TF_Sign_Detection/workspace/models/my_ssd_mobnet',\n",
       " 'OUTPUT_PATH': 'TF_Sign_Detection/workspace/models/my_ssd_mobnet/export',\n",
       " 'TFJS_PATH': 'TF_Sign_Detection/workspace/models/my_ssd_mobnet/tfjsexport',\n",
       " 'TFLITE_PATH': 'TF_Sign_Detection/workspace/models/my_ssd_mobnet/tfliteexport',\n",
       " 'PROTOC_PATH': 'TF_Sign_Detection/protoc'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('TF_Sign_Detection', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('TF_Sign_Detection','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('TF_Sign_Detection','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('TF_Sign_Detection', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('TF_Sign_Detection', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('TF_Sign_Detection', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('TF_Sign_Detection', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('TF_Sign_Detection', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('TF_Sign_Detection', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH':os.path.join('TF_Sign_Detection', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('TF_Sign_Detection', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('TF_Sign_Detection','protoc')\n",
    " }\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PIPELINE_CONFIG': 'TF_Sign_Detection/workspace/models/my_ssd_mobnet/pipeline.config',\n",
       " 'TF_RECORD_SCRIPT': 'TF_Sign_Detection/scripts/Generate_tfrecord_fromCSV.py',\n",
       " 'LABELMAP': 'TF_Sign_Detection/workspace/annotations/label_map.pbtxt'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('TF_Sign_Detection', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'TF_Sign_Detection/models'...\n",
      "remote: Enumerating objects: 70422, done.\u001b[K\n",
      "remote: Total 70422 (delta 0), reused 0 (delta 0), pack-reused 70422\u001b[K\n",
      "Receiving objects: 100% (70422/70422), 578.38 MiB | 5.93 MiB/s, done.\n",
      "Resolving deltas: 100% (49679/49679), done.\n",
      "Updating files: 100% (3242/3242), done.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running `brew update --preinstall`...\n",
      "\u001b[34m==>\u001b[0m \u001b[1mAuto-updated Homebrew!\u001b[0m\n",
      "Updated 2 taps (homebrew/core and homebrew/cask).\n",
      "\u001b[34m==>\u001b[0m \u001b[1mNew Formulae\u001b[0m\n",
      "epinio\n",
      "\u001b[34m==>\u001b[0m \u001b[1mUpdated Formulae\u001b[0m\n",
      "Updated 17 formulae.\n",
      "\u001b[34m==>\u001b[0m \u001b[1mUpdated Casks\u001b[0m\n",
      "Updated 5 casks.\n",
      "\n",
      "\u001b[33mWarning:\u001b[0m protobuf-c 1.4.0_1 is already installed and up-to-date.\n",
      "To reinstall 1.4.0_1, run:\n",
      "  brew reinstall protobuf-c\n",
      "Processing /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TF_Sign_Detection/models/research\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: avro-python3 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from object-detection==0.1) (1.10.2)\n",
      "Requirement already satisfied: apache-beam in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from object-detection==0.1) (2.37.0)\n",
      "Requirement already satisfied: pillow in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from object-detection==0.1) (9.0.1)\n",
      "Requirement already satisfied: lxml in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from object-detection==0.1) (4.8.0)\n",
      "Requirement already satisfied: matplotlib in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from object-detection==0.1) (3.2.0)\n",
      "Requirement already satisfied: Cython in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from object-detection==0.1) (0.29.28)\n",
      "Requirement already satisfied: contextlib2 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from object-detection==0.1) (21.6.0)\n",
      "Requirement already satisfied: tf-slim in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: six in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from object-detection==0.1) (1.16.0)\n",
      "Requirement already satisfied: pycocotools in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from object-detection==0.1) (2.0.4)\n",
      "Requirement already satisfied: lvis in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from object-detection==0.1) (0.5.3)\n",
      "Requirement already satisfied: scipy in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from object-detection==0.1) (1.7.3)\n",
      "Requirement already satisfied: pandas in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from object-detection==0.1) (1.3.5)\n",
      "Requirement already satisfied: tf-models-official>=2.5.1 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from object-detection==0.1) (2.8.0)\n",
      "Requirement already satisfied: tensorflow_io in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from object-detection==0.1) (0.24.0)\n",
      "Requirement already satisfied: keras in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from object-detection==0.1) (2.8.0)\n",
      "Requirement already satisfied: tensorflow-text~=2.8.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.8.1)\n",
      "Requirement already satisfied: seqeval in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
      "Requirement already satisfied: opencv-python-headless in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.5.2.52)\n",
      "Requirement already satisfied: sentencepiece in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.96)\n",
      "Requirement already satisfied: tensorflow-datasets in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.5.2)\n",
      "Requirement already satisfied: tensorflow~=2.8.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (8.0.0)\n",
      "Requirement already satisfied: tensorflow-addons in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.16.1)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.0)\n",
      "Requirement already satisfied: sacrebleu in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.0.0)\n",
      "Requirement already satisfied: pyyaml<6.0,>=5.1 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.1)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
      "Requirement already satisfied: gin-config in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.7.1)\n",
      "Requirement already satisfied: oauth2client in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.39.0)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from pandas->object-detection==0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from pandas->object-detection==0.1) (2021.3)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tf-slim->object-detection==0.1) (1.0.0)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (4.1.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (2.27.1)\n",
      "Requirement already satisfied: httplib2<0.20.0,>=0.8 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (0.19.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (1.4.10)\n",
      "Requirement already satisfied: protobuf<4,>=3.12.2 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (3.19.4)\n",
      "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (2.0.0)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (3.12.3)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (2.6.0)\n",
      "Requirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
      "Requirement already satisfied: orjson<4.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (3.6.7)\n",
      "Requirement already satisfied: grpcio<2,>=1.29.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (1.44.0)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (1.7)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (1.20.3)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from lvis->object-detection==0.1) (4.5.5.64)\n",
      "Requirement already satisfied: pyparsing>=2.4.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from lvis->object-detection==0.1) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from lvis->object-detection==0.1) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from lvis->object-detection==0.1) (0.11.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.24.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tensorflow_io->object-detection==0.1) (0.24.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=1.21.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
      "Requirement already satisfied: docopt in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
      "Requirement already satisfied: certifi in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n",
      "Requirement already satisfied: tqdm in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.63.0)\n",
      "Requirement already satisfied: urllib3 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.26.8)\n",
      "Requirement already satisfied: python-slugify in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.0.12)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (13.0.0)\n",
      "Requirement already satisfied: setuptools in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (60.9.3)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.5.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dm-tree~=0.1.1 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
      "Requirement already satisfied: regex in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2022.3.2)\n",
      "Requirement already satisfied: portalocker in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2.4.0)\n",
      "Requirement already satisfied: colorama in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.4.4)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
      "Requirement already satisfied: typeguard>=2.7 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.13.3)\n",
      "Requirement already satisfied: tensorflow-metadata in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.7.0)\n",
      "Requirement already satisfied: importlib-resources in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.4.0)\n",
      "Requirement already satisfied: promise in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.55.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.0.0)\n",
      "Requirement already satisfied: cached-property in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from h5py>=2.9.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from importlib-resources->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.7.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
      "Building wheels for collected packages: object-detection\n",
      "  Building wheel for object-detection (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1653456 sha256=f8a6c6a909ac9b05b064f8c5b88b277fca266e88abc6c77ebd357b3ddd2ff540\n",
      "  Stored in directory: /private/var/folders/c0/jhyh58254rx8htlc0km9zjs80000gp/T/pip-ephem-wheel-cache-j88w13sr/wheels/41/8f/8c/a1300a9fd9952f10da5a143fc060e4a1f3b87047b7d9811dbe\n",
      "Successfully built object-detection\n",
      "Installing collected packages: object-detection\n",
      "  Attempting uninstall: object-detection\n",
      "    Found existing installation: object-detection 0.1\n",
      "    Uninstalling object-detection-0.1:\n",
      "      Successfully uninstalled object-detection-0.1\n",
      "Successfully installed object-detection-0.1\n"
     ]
    }
   ],
   "source": [
    "if os.name=='posix':  \n",
    "    !brew install protobuf-c\n",
    "    !cd TF_Sign_Detection/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
    "    \n",
    "if os.name=='nt':\n",
    "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "    wget.download(url)\n",
    "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "    !cd TF_Sign_Detection/models/research/slim && pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tests under Python 3.7.4: /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/bin/python\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "2022-03-21 10:27:29.795812: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/object_detection/builders/model_builder.py:1100: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  logging.warn(('Building experimental DeepMAC meta-arch.'\n",
      "W0321 10:27:30.056422 4385451520 model_builder.py:1100] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.63s\n",
      "I0321 10:27:30.389621 4385451520 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.63s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.81s\n",
      "I0321 10:27:31.196959 4385451520 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.81s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.24s\n",
      "I0321 10:27:31.438201 4385451520 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.24s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.22s\n",
      "I0321 10:27:31.661285 4385451520 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.22s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.7s\n",
      "I0321 10:27:33.362864 4385451520 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.7s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I0321 10:27:33.363932 4385451520 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "I0321 10:27:33.387509 4385451520 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
      "I0321 10:27:33.405022 4385451520 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
      "I0321 10:27:33.420858 4385451520 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.1s\n",
      "I0321 10:27:33.521039 4385451520 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.1s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n",
      "I0321 10:27:33.611086 4385451520 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
      "I0321 10:27:33.703536 4385451520 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
      "I0321 10:27:33.794825 4385451520 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
      "I0321 10:27:33.883824 4385451520 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "I0321 10:27:33.907672 4385451520 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I0321 10:27:34.065361 4385451520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I0321 10:27:34.065486 4385451520 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
      "I0321 10:27:34.065539 4385451520 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
      "I0321 10:27:34.067528 4385451520 efficientnet_model.py:144] round_filter input=32 output=32\n",
      "I0321 10:27:34.081845 4385451520 efficientnet_model.py:144] round_filter input=32 output=32\n",
      "I0321 10:27:34.081968 4385451520 efficientnet_model.py:144] round_filter input=16 output=16\n",
      "I0321 10:27:34.142448 4385451520 efficientnet_model.py:144] round_filter input=16 output=16\n",
      "I0321 10:27:34.142584 4385451520 efficientnet_model.py:144] round_filter input=24 output=24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0321 10:27:34.276934 4385451520 efficientnet_model.py:144] round_filter input=24 output=24\n",
      "I0321 10:27:34.277061 4385451520 efficientnet_model.py:144] round_filter input=40 output=40\n",
      "I0321 10:27:34.420578 4385451520 efficientnet_model.py:144] round_filter input=40 output=40\n",
      "I0321 10:27:34.420705 4385451520 efficientnet_model.py:144] round_filter input=80 output=80\n",
      "I0321 10:27:34.611940 4385451520 efficientnet_model.py:144] round_filter input=80 output=80\n",
      "I0321 10:27:34.612061 4385451520 efficientnet_model.py:144] round_filter input=112 output=112\n",
      "I0321 10:27:34.804876 4385451520 efficientnet_model.py:144] round_filter input=112 output=112\n",
      "I0321 10:27:34.804997 4385451520 efficientnet_model.py:144] round_filter input=192 output=192\n",
      "I0321 10:27:35.082650 4385451520 efficientnet_model.py:144] round_filter input=192 output=192\n",
      "I0321 10:27:35.082778 4385451520 efficientnet_model.py:144] round_filter input=320 output=320\n",
      "I0321 10:27:35.160421 4385451520 efficientnet_model.py:144] round_filter input=1280 output=1280\n",
      "I0321 10:27:35.202159 4385451520 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0321 10:27:35.250410 4385451520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I0321 10:27:35.250536 4385451520 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
      "I0321 10:27:35.250601 4385451520 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n",
      "I0321 10:27:35.252215 4385451520 efficientnet_model.py:144] round_filter input=32 output=32\n",
      "I0321 10:27:35.266887 4385451520 efficientnet_model.py:144] round_filter input=32 output=32\n",
      "I0321 10:27:35.266993 4385451520 efficientnet_model.py:144] round_filter input=16 output=16\n",
      "I0321 10:27:35.368090 4385451520 efficientnet_model.py:144] round_filter input=16 output=16\n",
      "I0321 10:27:35.368212 4385451520 efficientnet_model.py:144] round_filter input=24 output=24\n",
      "I0321 10:27:35.690589 4385451520 efficientnet_model.py:144] round_filter input=24 output=24\n",
      "I0321 10:27:35.690739 4385451520 efficientnet_model.py:144] round_filter input=40 output=40\n",
      "I0321 10:27:35.889667 4385451520 efficientnet_model.py:144] round_filter input=40 output=40\n",
      "I0321 10:27:35.889822 4385451520 efficientnet_model.py:144] round_filter input=80 output=80\n",
      "I0321 10:27:36.163248 4385451520 efficientnet_model.py:144] round_filter input=80 output=80\n",
      "I0321 10:27:36.163406 4385451520 efficientnet_model.py:144] round_filter input=112 output=112\n",
      "I0321 10:27:36.437237 4385451520 efficientnet_model.py:144] round_filter input=112 output=112\n",
      "I0321 10:27:36.437369 4385451520 efficientnet_model.py:144] round_filter input=192 output=192\n",
      "I0321 10:27:36.796389 4385451520 efficientnet_model.py:144] round_filter input=192 output=192\n",
      "I0321 10:27:36.796545 4385451520 efficientnet_model.py:144] round_filter input=320 output=320\n",
      "I0321 10:27:36.954389 4385451520 efficientnet_model.py:144] round_filter input=1280 output=1280\n",
      "I0321 10:27:36.994604 4385451520 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0321 10:27:37.056423 4385451520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I0321 10:27:37.056551 4385451520 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
      "I0321 10:27:37.056607 4385451520 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n",
      "I0321 10:27:37.058095 4385451520 efficientnet_model.py:144] round_filter input=32 output=32\n",
      "I0321 10:27:37.070910 4385451520 efficientnet_model.py:144] round_filter input=32 output=32\n",
      "I0321 10:27:37.071045 4385451520 efficientnet_model.py:144] round_filter input=16 output=16\n",
      "I0321 10:27:37.183620 4385451520 efficientnet_model.py:144] round_filter input=16 output=16\n",
      "I0321 10:27:37.183743 4385451520 efficientnet_model.py:144] round_filter input=24 output=24\n",
      "I0321 10:27:37.380645 4385451520 efficientnet_model.py:144] round_filter input=24 output=24\n",
      "I0321 10:27:37.380797 4385451520 efficientnet_model.py:144] round_filter input=40 output=48\n",
      "I0321 10:27:37.580970 4385451520 efficientnet_model.py:144] round_filter input=40 output=48\n",
      "I0321 10:27:37.581125 4385451520 efficientnet_model.py:144] round_filter input=80 output=88\n",
      "I0321 10:27:37.852175 4385451520 efficientnet_model.py:144] round_filter input=80 output=88\n",
      "I0321 10:27:37.852337 4385451520 efficientnet_model.py:144] round_filter input=112 output=120\n",
      "I0321 10:27:38.126282 4385451520 efficientnet_model.py:144] round_filter input=112 output=120\n",
      "I0321 10:27:38.126438 4385451520 efficientnet_model.py:144] round_filter input=192 output=208\n",
      "I0321 10:27:38.489789 4385451520 efficientnet_model.py:144] round_filter input=192 output=208\n",
      "I0321 10:27:38.489933 4385451520 efficientnet_model.py:144] round_filter input=320 output=352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0321 10:27:38.663618 4385451520 efficientnet_model.py:144] round_filter input=1280 output=1408\n",
      "I0321 10:27:38.703455 4385451520 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0321 10:27:38.768221 4385451520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I0321 10:27:38.768378 4385451520 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
      "I0321 10:27:38.768435 4385451520 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n",
      "I0321 10:27:38.770133 4385451520 efficientnet_model.py:144] round_filter input=32 output=40\n",
      "I0321 10:27:38.783207 4385451520 efficientnet_model.py:144] round_filter input=32 output=40\n",
      "I0321 10:27:38.783344 4385451520 efficientnet_model.py:144] round_filter input=16 output=24\n",
      "I0321 10:27:38.892369 4385451520 efficientnet_model.py:144] round_filter input=16 output=24\n",
      "I0321 10:27:38.892528 4385451520 efficientnet_model.py:144] round_filter input=24 output=32\n",
      "I0321 10:27:39.091279 4385451520 efficientnet_model.py:144] round_filter input=24 output=32\n",
      "I0321 10:27:39.091447 4385451520 efficientnet_model.py:144] round_filter input=40 output=48\n",
      "I0321 10:27:39.291205 4385451520 efficientnet_model.py:144] round_filter input=40 output=48\n",
      "I0321 10:27:39.291345 4385451520 efficientnet_model.py:144] round_filter input=80 output=96\n",
      "I0321 10:27:39.813719 4385451520 efficientnet_model.py:144] round_filter input=80 output=96\n",
      "I0321 10:27:39.813874 4385451520 efficientnet_model.py:144] round_filter input=112 output=136\n",
      "I0321 10:27:40.158352 4385451520 efficientnet_model.py:144] round_filter input=112 output=136\n",
      "I0321 10:27:40.158507 4385451520 efficientnet_model.py:144] round_filter input=192 output=232\n",
      "I0321 10:27:40.602458 4385451520 efficientnet_model.py:144] round_filter input=192 output=232\n",
      "I0321 10:27:40.602588 4385451520 efficientnet_model.py:144] round_filter input=320 output=384\n",
      "I0321 10:27:40.770171 4385451520 efficientnet_model.py:144] round_filter input=1280 output=1536\n",
      "I0321 10:27:40.816134 4385451520 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0321 10:27:40.883628 4385451520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I0321 10:27:40.883755 4385451520 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
      "I0321 10:27:40.883810 4385451520 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
      "I0321 10:27:40.885576 4385451520 efficientnet_model.py:144] round_filter input=32 output=48\n",
      "I0321 10:27:40.902136 4385451520 efficientnet_model.py:144] round_filter input=32 output=48\n",
      "I0321 10:27:40.902256 4385451520 efficientnet_model.py:144] round_filter input=16 output=24\n",
      "I0321 10:27:41.010704 4385451520 efficientnet_model.py:144] round_filter input=16 output=24\n",
      "I0321 10:27:41.010856 4385451520 efficientnet_model.py:144] round_filter input=24 output=32\n",
      "I0321 10:27:41.272954 4385451520 efficientnet_model.py:144] round_filter input=24 output=32\n",
      "I0321 10:27:41.273112 4385451520 efficientnet_model.py:144] round_filter input=40 output=56\n",
      "I0321 10:27:41.540961 4385451520 efficientnet_model.py:144] round_filter input=40 output=56\n",
      "I0321 10:27:41.541096 4385451520 efficientnet_model.py:144] round_filter input=80 output=112\n",
      "I0321 10:27:41.947816 4385451520 efficientnet_model.py:144] round_filter input=80 output=112\n",
      "I0321 10:27:41.947974 4385451520 efficientnet_model.py:144] round_filter input=112 output=160\n",
      "I0321 10:27:42.369419 4385451520 efficientnet_model.py:144] round_filter input=112 output=160\n",
      "I0321 10:27:42.369554 4385451520 efficientnet_model.py:144] round_filter input=192 output=272\n",
      "I0321 10:27:42.985509 4385451520 efficientnet_model.py:144] round_filter input=192 output=272\n",
      "I0321 10:27:42.985661 4385451520 efficientnet_model.py:144] round_filter input=320 output=448\n",
      "I0321 10:27:43.166832 4385451520 efficientnet_model.py:144] round_filter input=1280 output=1792\n",
      "I0321 10:27:43.217437 4385451520 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0321 10:27:43.291623 4385451520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I0321 10:27:43.291747 4385451520 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
      "I0321 10:27:43.291800 4385451520 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
      "I0321 10:27:43.293241 4385451520 efficientnet_model.py:144] round_filter input=32 output=48\n",
      "I0321 10:27:43.305978 4385451520 efficientnet_model.py:144] round_filter input=32 output=48\n",
      "I0321 10:27:43.306084 4385451520 efficientnet_model.py:144] round_filter input=16 output=24\n",
      "I0321 10:27:43.453414 4385451520 efficientnet_model.py:144] round_filter input=16 output=24\n",
      "I0321 10:27:43.453540 4385451520 efficientnet_model.py:144] round_filter input=24 output=40\n",
      "I0321 10:27:43.980006 4385451520 efficientnet_model.py:144] round_filter input=24 output=40\n",
      "I0321 10:27:43.980159 4385451520 efficientnet_model.py:144] round_filter input=40 output=64\n",
      "I0321 10:27:44.316079 4385451520 efficientnet_model.py:144] round_filter input=40 output=64\n",
      "I0321 10:27:44.316232 4385451520 efficientnet_model.py:144] round_filter input=80 output=128\n",
      "I0321 10:27:44.799630 4385451520 efficientnet_model.py:144] round_filter input=80 output=128\n",
      "I0321 10:27:44.799757 4385451520 efficientnet_model.py:144] round_filter input=112 output=176\n",
      "I0321 10:27:45.298682 4385451520 efficientnet_model.py:144] round_filter input=112 output=176\n",
      "I0321 10:27:45.298839 4385451520 efficientnet_model.py:144] round_filter input=192 output=304\n",
      "I0321 10:27:46.023346 4385451520 efficientnet_model.py:144] round_filter input=192 output=304\n",
      "I0321 10:27:46.023503 4385451520 efficientnet_model.py:144] round_filter input=320 output=512\n",
      "I0321 10:27:46.328150 4385451520 efficientnet_model.py:144] round_filter input=1280 output=2048\n",
      "I0321 10:27:46.380736 4385451520 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0321 10:27:46.472407 4385451520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I0321 10:27:46.472530 4385451520 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
      "I0321 10:27:46.472585 4385451520 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
      "I0321 10:27:46.474078 4385451520 efficientnet_model.py:144] round_filter input=32 output=56\n",
      "I0321 10:27:46.486569 4385451520 efficientnet_model.py:144] round_filter input=32 output=56\n",
      "I0321 10:27:46.486720 4385451520 efficientnet_model.py:144] round_filter input=16 output=32\n",
      "I0321 10:27:46.646116 4385451520 efficientnet_model.py:144] round_filter input=16 output=32\n",
      "I0321 10:27:46.646267 4385451520 efficientnet_model.py:144] round_filter input=24 output=40\n",
      "I0321 10:27:47.042565 4385451520 efficientnet_model.py:144] round_filter input=24 output=40\n",
      "I0321 10:27:47.042721 4385451520 efficientnet_model.py:144] round_filter input=40 output=72\n",
      "I0321 10:27:47.444308 4385451520 efficientnet_model.py:144] round_filter input=40 output=72\n",
      "I0321 10:27:47.444463 4385451520 efficientnet_model.py:144] round_filter input=80 output=144\n",
      "I0321 10:27:47.998816 4385451520 efficientnet_model.py:144] round_filter input=80 output=144\n",
      "I0321 10:27:47.998970 4385451520 efficientnet_model.py:144] round_filter input=112 output=200\n",
      "I0321 10:27:48.786557 4385451520 efficientnet_model.py:144] round_filter input=112 output=200\n",
      "I0321 10:27:48.786712 4385451520 efficientnet_model.py:144] round_filter input=192 output=344\n",
      "I0321 10:27:49.709115 4385451520 efficientnet_model.py:144] round_filter input=192 output=344\n",
      "I0321 10:27:49.709274 4385451520 efficientnet_model.py:144] round_filter input=320 output=576\n",
      "I0321 10:27:50.051164 4385451520 efficientnet_model.py:144] round_filter input=1280 output=2304\n",
      "I0321 10:27:50.121612 4385451520 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0321 10:27:50.217821 4385451520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I0321 10:27:50.217946 4385451520 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
      "I0321 10:27:50.217999 4385451520 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
      "I0321 10:27:50.219431 4385451520 efficientnet_model.py:144] round_filter input=32 output=64\n",
      "I0321 10:27:50.231534 4385451520 efficientnet_model.py:144] round_filter input=32 output=64\n",
      "I0321 10:27:50.231637 4385451520 efficientnet_model.py:144] round_filter input=16 output=32\n",
      "I0321 10:27:50.430464 4385451520 efficientnet_model.py:144] round_filter input=16 output=32\n",
      "I0321 10:27:50.430590 4385451520 efficientnet_model.py:144] round_filter input=24 output=48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0321 10:27:50.877171 4385451520 efficientnet_model.py:144] round_filter input=24 output=48\n",
      "I0321 10:27:50.877327 4385451520 efficientnet_model.py:144] round_filter input=40 output=80\n",
      "I0321 10:27:51.349400 4385451520 efficientnet_model.py:144] round_filter input=40 output=80\n",
      "I0321 10:27:51.349558 4385451520 efficientnet_model.py:144] round_filter input=80 output=160\n",
      "I0321 10:27:52.054419 4385451520 efficientnet_model.py:144] round_filter input=80 output=160\n",
      "I0321 10:27:52.054573 4385451520 efficientnet_model.py:144] round_filter input=112 output=224\n",
      "I0321 10:27:52.798913 4385451520 efficientnet_model.py:144] round_filter input=112 output=224\n",
      "I0321 10:27:52.799058 4385451520 efficientnet_model.py:144] round_filter input=192 output=384\n",
      "I0321 10:27:54.179843 4385451520 efficientnet_model.py:144] round_filter input=192 output=384\n",
      "I0321 10:27:54.180001 4385451520 efficientnet_model.py:144] round_filter input=320 output=640\n",
      "I0321 10:27:54.672474 4385451520 efficientnet_model.py:144] round_filter input=1280 output=2560\n",
      "I0321 10:27:54.735755 4385451520 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 20.95s\n",
      "I0321 10:27:54.853012 4385451520 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 20.95s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "I0321 10:27:54.861803 4385451520 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I0321 10:27:54.863313 4385451520 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I0321 10:27:54.863665 4385451520 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I0321 10:27:54.865061 4385451520 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "I0321 10:27:54.866312 4385451520 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I0321 10:27:54.866618 4385451520 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I0321 10:27:54.867493 4385451520 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 25.112s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verify Installation\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall protobuf matplotlib -y\n",
    "!pip install protobuf matplotlib==3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-21 11:05:34--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
      "Résolution de download.tensorflow.org (download.tensorflow.org)… 172.217.22.144\n",
      "Connexion à download.tensorflow.org (download.tensorflow.org)|172.217.22.144|:80… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 20515344 (20M) [application/x-tar]\n",
      "Sauvegarde en : « ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz »\n",
      "\n",
      "ssd_mobilenet_v2_fp 100%[===================>]  19,56M  4,41MB/s    ds 10s     \n",
      "\n",
      "2022-03-21 11:05:45 (1,96 MB/s) — « ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz » sauvegardé [20515344/20515344]\n",
      "\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "if os.name =='posix':\n",
    "    !wget {PRETRAINED_MODEL_URL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "if os.name == 'nt':\n",
    "    wget.download(PRETRAINED_MODEL_URL)\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Overview\n",
    "labels = [  {'name': 'Speed limit (20km/h)','id':1},\n",
    "            {'name':'Speed limit (30km/h)', 'id':2},\n",
    "            {'name':'Speed limit (50km/h)', 'id':3},\n",
    "            {'name':'Speed limit (60km/h)', 'id':4},\n",
    "            {'name':'Speed limit (70km/h)', 'id':5},\n",
    "            {'name':'Speed limit (80km/h)', 'id':6},\n",
    "            {'name':'End of speed limit (80km/h)', 'id':7},\n",
    "            {'name':'Speed limit (100km/h)', 'id':8},\n",
    "            {'name':'Speed limit (120km/h)', 'id':9},\n",
    "            {'name':'No passing', 'id':10},\n",
    "            {'name':'No passing veh over 3.5 tons', 'id':11},\n",
    "            {'name':'Right-of-way at intersection', 'id':12},\n",
    "            {'name':'Priority road', 'id':13},\n",
    "            {'name':'Yield', 'id':14},\n",
    "            {'name':'Stop', 'id':15},\n",
    "            {'name':'No vehicles', 'id':16},\n",
    "            {'name':'Veh > 3.5 tons prohibited', 'id':17},\n",
    "            {'name':'No entry', 'id':18},\n",
    "            {'name':'General caution', 'id':19},\n",
    "            {'name':'Dangerous curve left', 'id':20},\n",
    "            {'name':'Dangerous curve right', 'id':21},\n",
    "            {'name':'Double curve',  'id':22},\n",
    "            {'name':'Bumpy road',  'id':23},\n",
    "            {'name':'Slippery road',  'id':24},\n",
    "            {'name':'Road narrows on the right',  'id':25},\n",
    "            {'name':'Road work',  'id':26},\n",
    "            {'name':'Traffic signals',  'id':27},\n",
    "            {'name':'Pedestrians',  'id':28},\n",
    "            {'name':'Children crossing',  'id':29},\n",
    "            {'name':'Bicycles crossing',  'id':30},\n",
    "            {'name':'Beware of ice/snow', 'id':31},\n",
    "            {'name':'Wild animals crossing',  'id':32},\n",
    "            {'name':'End speed + passing limits',  'id':33},\n",
    "            {'name':'Turn right ahead',  'id':34},\n",
    "            {'name':'Turn left ahead',  'id':35},\n",
    "            {'name':'Ahead only',  'id':36},\n",
    "            {'name':'Go straight or right',  'id':37},\n",
    "            {'name':'Go straight or left',  'id':38},\n",
    "            {'name':'Keep right',  'id':39},\n",
    "            {'name':'Keep left',  'id':40},\n",
    "            {'name':'Roundabout mandatory',  'id':41},\n",
    "            {'name':'End of no passing',  'id':42},\n",
    "            {'name':'End no passing veh > 3.5 tons' , 'id':43}\n",
    "]\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create TF records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TF_Sign_Detection/scripts/Generate_tfrecord_fromCSV.py'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{files['TF_RECORD_SCRIPT']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: TF_Sign_Detection/workspace/annotations/train.record\r\n"
     ]
    }
   ],
   "source": [
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'Train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} -i {os.path.join(paths['IMAGE_PATH'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: TF_Sign_Detection/workspace/annotations/test.record\r\n"
     ]
    }
   ],
   "source": [
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'Test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} -i {os.path.join(paths['IMAGE_PATH'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Copy Model Config to Training Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TF_Sign_Detection/workspace/pre-trained-models'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(paths['PRETRAINED_MODEL_PATH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Update Config For Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ssd {\n",
       "   num_classes: 90\n",
       "   image_resizer {\n",
       "     fixed_shape_resizer {\n",
       "       height: 320\n",
       "       width: 320\n",
       "     }\n",
       "   }\n",
       "   feature_extractor {\n",
       "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
       "     depth_multiplier: 1.0\n",
       "     min_depth: 16\n",
       "     conv_hyperparams {\n",
       "       regularizer {\n",
       "         l2_regularizer {\n",
       "           weight: 3.9999998989515007e-05\n",
       "         }\n",
       "       }\n",
       "       initializer {\n",
       "         random_normal_initializer {\n",
       "           mean: 0.0\n",
       "           stddev: 0.009999999776482582\n",
       "         }\n",
       "       }\n",
       "       activation: RELU_6\n",
       "       batch_norm {\n",
       "         decay: 0.996999979019165\n",
       "         scale: true\n",
       "         epsilon: 0.0010000000474974513\n",
       "       }\n",
       "     }\n",
       "     use_depthwise: true\n",
       "     override_base_feature_extractor_hyperparams: true\n",
       "     fpn {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       additional_layer_depth: 128\n",
       "     }\n",
       "   }\n",
       "   box_coder {\n",
       "     faster_rcnn_box_coder {\n",
       "       y_scale: 10.0\n",
       "       x_scale: 10.0\n",
       "       height_scale: 5.0\n",
       "       width_scale: 5.0\n",
       "     }\n",
       "   }\n",
       "   matcher {\n",
       "     argmax_matcher {\n",
       "       matched_threshold: 0.5\n",
       "       unmatched_threshold: 0.5\n",
       "       ignore_thresholds: false\n",
       "       negatives_lower_than_unmatched: true\n",
       "       force_match_for_each_row: true\n",
       "       use_matmul_gather: true\n",
       "     }\n",
       "   }\n",
       "   similarity_calculator {\n",
       "     iou_similarity {\n",
       "     }\n",
       "   }\n",
       "   box_predictor {\n",
       "     weight_shared_convolutional_box_predictor {\n",
       "       conv_hyperparams {\n",
       "         regularizer {\n",
       "           l2_regularizer {\n",
       "             weight: 3.9999998989515007e-05\n",
       "           }\n",
       "         }\n",
       "         initializer {\n",
       "           random_normal_initializer {\n",
       "             mean: 0.0\n",
       "             stddev: 0.009999999776482582\n",
       "           }\n",
       "         }\n",
       "         activation: RELU_6\n",
       "         batch_norm {\n",
       "           decay: 0.996999979019165\n",
       "           scale: true\n",
       "           epsilon: 0.0010000000474974513\n",
       "         }\n",
       "       }\n",
       "       depth: 128\n",
       "       num_layers_before_predictor: 4\n",
       "       kernel_size: 3\n",
       "       class_prediction_bias_init: -4.599999904632568\n",
       "       share_prediction_tower: true\n",
       "       use_depthwise: true\n",
       "     }\n",
       "   }\n",
       "   anchor_generator {\n",
       "     multiscale_anchor_generator {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       anchor_scale: 4.0\n",
       "       aspect_ratios: 1.0\n",
       "       aspect_ratios: 2.0\n",
       "       aspect_ratios: 0.5\n",
       "       scales_per_octave: 2\n",
       "     }\n",
       "   }\n",
       "   post_processing {\n",
       "     batch_non_max_suppression {\n",
       "       score_threshold: 9.99999993922529e-09\n",
       "       iou_threshold: 0.6000000238418579\n",
       "       max_detections_per_class: 100\n",
       "       max_total_detections: 100\n",
       "       use_static_shapes: false\n",
       "     }\n",
       "     score_converter: SIGMOID\n",
       "   }\n",
       "   normalize_loss_by_num_matches: true\n",
       "   loss {\n",
       "     localization_loss {\n",
       "       weighted_smooth_l1 {\n",
       "       }\n",
       "     }\n",
       "     classification_loss {\n",
       "       weighted_sigmoid_focal {\n",
       "         gamma: 2.0\n",
       "         alpha: 0.25\n",
       "       }\n",
       "     }\n",
       "     classification_weight: 1.0\n",
       "     localization_weight: 1.0\n",
       "   }\n",
       "   encode_background_as_zeros: true\n",
       "   normalize_loc_loss_by_codesize: true\n",
       "   inplace_batchnorm_update: true\n",
       "   freeze_batchnorm: false\n",
       " },\n",
       " 'train_config': batch_size: 128\n",
       " data_augmentation_options {\n",
       "   random_horizontal_flip {\n",
       "   }\n",
       " }\n",
       " data_augmentation_options {\n",
       "   random_crop_image {\n",
       "     min_object_covered: 0.0\n",
       "     min_aspect_ratio: 0.75\n",
       "     max_aspect_ratio: 3.0\n",
       "     min_area: 0.75\n",
       "     max_area: 1.0\n",
       "     overlap_thresh: 0.0\n",
       "   }\n",
       " }\n",
       " sync_replicas: true\n",
       " optimizer {\n",
       "   momentum_optimizer {\n",
       "     learning_rate {\n",
       "       cosine_decay_learning_rate {\n",
       "         learning_rate_base: 0.07999999821186066\n",
       "         total_steps: 50000\n",
       "         warmup_learning_rate: 0.026666000485420227\n",
       "         warmup_steps: 1000\n",
       "       }\n",
       "     }\n",
       "     momentum_optimizer_value: 0.8999999761581421\n",
       "   }\n",
       "   use_moving_average: false\n",
       " }\n",
       " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
       " num_steps: 50000\n",
       " startup_delay_steps: 0.0\n",
       " replicas_to_aggregate: 8\n",
       " max_number_of_boxes: 100\n",
       " unpad_groundtruth_tensors: false\n",
       " fine_tune_checkpoint_type: \"classification\"\n",
       " fine_tune_checkpoint_version: V2,\n",
       " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " },\n",
       " 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
       " use_moving_averages: false,\n",
       " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " }\n",
       " ],\n",
       " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " }}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model {\n",
       "  ssd {\n",
       "    num_classes: 90\n",
       "    image_resizer {\n",
       "      fixed_shape_resizer {\n",
       "        height: 320\n",
       "        width: 320\n",
       "      }\n",
       "    }\n",
       "    feature_extractor {\n",
       "      type: \"ssd_mobilenet_v2_fpn_keras\"\n",
       "      depth_multiplier: 1.0\n",
       "      min_depth: 16\n",
       "      conv_hyperparams {\n",
       "        regularizer {\n",
       "          l2_regularizer {\n",
       "            weight: 3.9999998989515007e-05\n",
       "          }\n",
       "        }\n",
       "        initializer {\n",
       "          random_normal_initializer {\n",
       "            mean: 0.0\n",
       "            stddev: 0.009999999776482582\n",
       "          }\n",
       "        }\n",
       "        activation: RELU_6\n",
       "        batch_norm {\n",
       "          decay: 0.996999979019165\n",
       "          scale: true\n",
       "          epsilon: 0.0010000000474974513\n",
       "        }\n",
       "      }\n",
       "      use_depthwise: true\n",
       "      override_base_feature_extractor_hyperparams: true\n",
       "      fpn {\n",
       "        min_level: 3\n",
       "        max_level: 7\n",
       "        additional_layer_depth: 128\n",
       "      }\n",
       "    }\n",
       "    box_coder {\n",
       "      faster_rcnn_box_coder {\n",
       "        y_scale: 10.0\n",
       "        x_scale: 10.0\n",
       "        height_scale: 5.0\n",
       "        width_scale: 5.0\n",
       "      }\n",
       "    }\n",
       "    matcher {\n",
       "      argmax_matcher {\n",
       "        matched_threshold: 0.5\n",
       "        unmatched_threshold: 0.5\n",
       "        ignore_thresholds: false\n",
       "        negatives_lower_than_unmatched: true\n",
       "        force_match_for_each_row: true\n",
       "        use_matmul_gather: true\n",
       "      }\n",
       "    }\n",
       "    similarity_calculator {\n",
       "      iou_similarity {\n",
       "      }\n",
       "    }\n",
       "    box_predictor {\n",
       "      weight_shared_convolutional_box_predictor {\n",
       "        conv_hyperparams {\n",
       "          regularizer {\n",
       "            l2_regularizer {\n",
       "              weight: 3.9999998989515007e-05\n",
       "            }\n",
       "          }\n",
       "          initializer {\n",
       "            random_normal_initializer {\n",
       "              mean: 0.0\n",
       "              stddev: 0.009999999776482582\n",
       "            }\n",
       "          }\n",
       "          activation: RELU_6\n",
       "          batch_norm {\n",
       "            decay: 0.996999979019165\n",
       "            scale: true\n",
       "            epsilon: 0.0010000000474974513\n",
       "          }\n",
       "        }\n",
       "        depth: 128\n",
       "        num_layers_before_predictor: 4\n",
       "        kernel_size: 3\n",
       "        class_prediction_bias_init: -4.599999904632568\n",
       "        share_prediction_tower: true\n",
       "        use_depthwise: true\n",
       "      }\n",
       "    }\n",
       "    anchor_generator {\n",
       "      multiscale_anchor_generator {\n",
       "        min_level: 3\n",
       "        max_level: 7\n",
       "        anchor_scale: 4.0\n",
       "        aspect_ratios: 1.0\n",
       "        aspect_ratios: 2.0\n",
       "        aspect_ratios: 0.5\n",
       "        scales_per_octave: 2\n",
       "      }\n",
       "    }\n",
       "    post_processing {\n",
       "      batch_non_max_suppression {\n",
       "        score_threshold: 9.99999993922529e-09\n",
       "        iou_threshold: 0.6000000238418579\n",
       "        max_detections_per_class: 100\n",
       "        max_total_detections: 100\n",
       "        use_static_shapes: false\n",
       "      }\n",
       "      score_converter: SIGMOID\n",
       "    }\n",
       "    normalize_loss_by_num_matches: true\n",
       "    loss {\n",
       "      localization_loss {\n",
       "        weighted_smooth_l1 {\n",
       "        }\n",
       "      }\n",
       "      classification_loss {\n",
       "        weighted_sigmoid_focal {\n",
       "          gamma: 2.0\n",
       "          alpha: 0.25\n",
       "        }\n",
       "      }\n",
       "      classification_weight: 1.0\n",
       "      localization_weight: 1.0\n",
       "    }\n",
       "    encode_background_as_zeros: true\n",
       "    normalize_loc_loss_by_codesize: true\n",
       "    inplace_batchnorm_update: true\n",
       "    freeze_batchnorm: false\n",
       "  }\n",
       "}\n",
       "train_config {\n",
       "  batch_size: 128\n",
       "  data_augmentation_options {\n",
       "    random_horizontal_flip {\n",
       "    }\n",
       "  }\n",
       "  data_augmentation_options {\n",
       "    random_crop_image {\n",
       "      min_object_covered: 0.0\n",
       "      min_aspect_ratio: 0.75\n",
       "      max_aspect_ratio: 3.0\n",
       "      min_area: 0.75\n",
       "      max_area: 1.0\n",
       "      overlap_thresh: 0.0\n",
       "    }\n",
       "  }\n",
       "  sync_replicas: true\n",
       "  optimizer {\n",
       "    momentum_optimizer {\n",
       "      learning_rate {\n",
       "        cosine_decay_learning_rate {\n",
       "          learning_rate_base: 0.07999999821186066\n",
       "          total_steps: 50000\n",
       "          warmup_learning_rate: 0.026666000485420227\n",
       "          warmup_steps: 1000\n",
       "        }\n",
       "      }\n",
       "      momentum_optimizer_value: 0.8999999761581421\n",
       "    }\n",
       "    use_moving_average: false\n",
       "  }\n",
       "  fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
       "  num_steps: 50000\n",
       "  startup_delay_steps: 0.0\n",
       "  replicas_to_aggregate: 8\n",
       "  max_number_of_boxes: 100\n",
       "  unpad_groundtruth_tensors: false\n",
       "  fine_tune_checkpoint_type: \"classification\"\n",
       "  fine_tune_checkpoint_version: V2\n",
       "}\n",
       "train_input_reader {\n",
       "  label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       "  tf_record_input_reader {\n",
       "    input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       "  }\n",
       "}\n",
       "eval_config {\n",
       "  metrics_set: \"coco_detection_metrics\"\n",
       "  use_moving_averages: false\n",
       "}\n",
       "eval_input_reader {\n",
       "  label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       "  shuffle: false\n",
       "  num_epochs: 1\n",
       "  tf_record_input_reader {\n",
       "    input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.model.ssd.image_resizer.fixed_shape_resizer.height = 320\n",
    "pipeline_config.model.ssd.image_resizer.fixed_shape_resizer.width = 320\n",
    "pipeline_config.train_config.batch_size =4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TF_Sign_Detection/workspace/annotations/label_map.pbtxt'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_config.eval_input_reader[0].label_map_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python-headless==4.5.2.52 in ./TFSD/lib/python3.7/site-packages (4.5.2.52)\n",
      "Requirement already satisfied: numpy>=1.14.5 in ./TFSD/lib/python3.7/site-packages (from opencv-python-headless==4.5.2.52) (1.21.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python-headless==4.5.2.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=4000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TF_Sign_Detection/models/research/object_detection/model_main_tf2.py'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_SCRIPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TF_Sign_Detection/workspace/models/my_ssd_mobnet'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths['CHECKPOINT_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TF_Sign_Detection/workspace/models/my_ssd_mobnet/pipeline.config'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files['PIPELINE_CONFIG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python TF_Sign_Detection/models/research/object_detection/model_main_tf2.py --model_dir=TF_Sign_Detection/workspace/models/my_ssd_mobnet --pipeline_config_path=TF_Sign_Detection/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=4000\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-21 11:24:45.082906: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "W0321 11:24:45.090091 4628336128 cross_device_ops.py:1386] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "I0321 11:24:45.201093 4628336128 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 4000\n",
      "I0321 11:24:45.208651 4628336128 config_util.py:552] Maybe overwriting train_steps: 4000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0321 11:24:45.208824 4628336128 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0321 11:24:45.252739 4628336128 deprecation.py:343] From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['TF_Sign_Detection/workspace/annotations/train.record']\n",
      "I0321 11:24:45.276031 4628336128 dataset_builder.py:163] Reading unweighted datasets: ['TF_Sign_Detection/workspace/annotations/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['TF_Sign_Detection/workspace/annotations/train.record']\n",
      "I0321 11:24:45.277424 4628336128 dataset_builder.py:80] Reading record datasets for input file: ['TF_Sign_Detection/workspace/annotations/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0321 11:24:45.277580 4628336128 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0321 11:24:45.277637 4628336128 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0321 11:24:45.400962 4628336128 deprecation.py:343] From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0321 11:24:45.505548 4628336128 deprecation.py:343] From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0321 11:24:52.063024 4628336128 deprecation.py:343] From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0321 11:24:55.000395 4628336128 deprecation.py:343] From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0321 11:24:56.588689 4628336128 deprecation.py:343] From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "2022-03-21 11:24:59.401610: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "/Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "WARNING:tensorflow:From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0321 11:25:17.995455 123145381007360 deprecation.py:547] From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "INFO:tensorflow:Step 100 per-step time 1.282s\n",
      "I0321 11:27:25.819786 4628336128 model_lib_v2.py:707] Step 100 per-step time 1.282s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.18424529,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.15314911,\n",
      " 'Loss/total_loss': 0.33739442,\n",
      " 'learning_rate': 0.0319994}\n",
      "I0321 11:27:25.820162 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.18424529,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.15314911,\n",
      " 'Loss/total_loss': 0.33739442,\n",
      " 'learning_rate': 0.0319994}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step 200 per-step time 1.038s\n",
      "I0321 11:29:09.641758 4628336128 model_lib_v2.py:707] Step 200 per-step time 1.038s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.013031347,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.15274061,\n",
      " 'Loss/total_loss': 0.16577196,\n",
      " 'learning_rate': 0.0373328}\n",
      "I0321 11:29:09.642054 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.013031347,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.15274061,\n",
      " 'Loss/total_loss': 0.16577196,\n",
      " 'learning_rate': 0.0373328}\n",
      "INFO:tensorflow:Step 300 per-step time 1.108s\n",
      "I0321 11:31:00.465830 4628336128 model_lib_v2.py:707] Step 300 per-step time 1.108s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00557354,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.15226151,\n",
      " 'Loss/total_loss': 0.15783505,\n",
      " 'learning_rate': 0.0426662}\n",
      "I0321 11:31:00.466061 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00557354,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.15226151,\n",
      " 'Loss/total_loss': 0.15783505,\n",
      " 'learning_rate': 0.0426662}\n",
      "INFO:tensorflow:Step 400 per-step time 1.045s\n",
      "I0321 11:32:45.005882 4628336128 model_lib_v2.py:707] Step 400 per-step time 1.045s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.003381785,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.1517183,\n",
      " 'Loss/total_loss': 0.15510009,\n",
      " 'learning_rate': 0.047999598}\n",
      "I0321 11:32:45.006124 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.003381785,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.1517183,\n",
      " 'Loss/total_loss': 0.15510009,\n",
      " 'learning_rate': 0.047999598}\n",
      "INFO:tensorflow:Step 500 per-step time 1.040s\n",
      "I0321 11:34:28.967375 4628336128 model_lib_v2.py:707] Step 500 per-step time 1.040s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0022120166,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.15111229,\n",
      " 'Loss/total_loss': 0.1533243,\n",
      " 'learning_rate': 0.053333}\n",
      "I0321 11:34:28.967713 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.0022120166,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.15111229,\n",
      " 'Loss/total_loss': 0.1533243,\n",
      " 'learning_rate': 0.053333}\n",
      "INFO:tensorflow:Step 600 per-step time 16.031s\n",
      "I0321 12:01:12.099107 4628336128 model_lib_v2.py:707] Step 600 per-step time 16.031s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0015968168,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.15044433,\n",
      " 'Loss/total_loss': 0.15204115,\n",
      " 'learning_rate': 0.0586664}\n",
      "I0321 12:01:12.101435 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.0015968168,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.15044433,\n",
      " 'Loss/total_loss': 0.15204115,\n",
      " 'learning_rate': 0.0586664}\n",
      "INFO:tensorflow:Step 700 per-step time 1.312s\n",
      "I0321 12:03:23.290949 4628336128 model_lib_v2.py:707] Step 700 per-step time 1.312s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0012703103,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.14971529,\n",
      " 'Loss/total_loss': 0.1509856,\n",
      " 'learning_rate': 0.0639998}\n",
      "I0321 12:03:23.291191 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.0012703103,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.14971529,\n",
      " 'Loss/total_loss': 0.1509856,\n",
      " 'learning_rate': 0.0639998}\n",
      "INFO:tensorflow:Step 800 per-step time 28.717s\n",
      "I0321 12:51:14.962527 4628336128 model_lib_v2.py:707] Step 800 per-step time 28.717s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00097101484,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.14892611,\n",
      " 'Loss/total_loss': 0.14989713,\n",
      " 'learning_rate': 0.069333196}\n",
      "I0321 12:51:14.962770 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00097101484,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.14892611,\n",
      " 'Loss/total_loss': 0.14989713,\n",
      " 'learning_rate': 0.069333196}\n",
      "INFO:tensorflow:Step 900 per-step time 1.074s\n",
      "I0321 12:53:02.401757 4628336128 model_lib_v2.py:707] Step 900 per-step time 1.074s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00091050233,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.14807777,\n",
      " 'Loss/total_loss': 0.14898828,\n",
      " 'learning_rate': 0.074666604}\n",
      "I0321 12:53:02.402098 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00091050233,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.14807777,\n",
      " 'Loss/total_loss': 0.14898828,\n",
      " 'learning_rate': 0.074666604}\n",
      "INFO:tensorflow:Step 1000 per-step time 1.207s\n",
      "I0321 12:55:03.066393 4628336128 model_lib_v2.py:707] Step 1000 per-step time 1.207s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00067791063,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.14717142,\n",
      " 'Loss/total_loss': 0.14784934,\n",
      " 'learning_rate': 0.08}\n",
      "I0321 12:55:03.066653 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00067791063,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.14717142,\n",
      " 'Loss/total_loss': 0.14784934,\n",
      " 'learning_rate': 0.08}\n",
      "INFO:tensorflow:Step 1100 per-step time 1.267s\n",
      "I0321 12:57:09.738801 4628336128 model_lib_v2.py:707] Step 1100 per-step time 1.267s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0005941974,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.14623344,\n",
      " 'Loss/total_loss': 0.14682764,\n",
      " 'learning_rate': 0.07999918}\n",
      "I0321 12:57:09.739159 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.0005941974,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.14623344,\n",
      " 'Loss/total_loss': 0.14682764,\n",
      " 'learning_rate': 0.07999918}\n",
      "INFO:tensorflow:Step 1200 per-step time 1.278s\n",
      "I0321 12:59:17.564615 4628336128 model_lib_v2.py:707] Step 1200 per-step time 1.278s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0005826872,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.14530078,\n",
      " 'Loss/total_loss': 0.14588346,\n",
      " 'learning_rate': 0.079996705}\n",
      "I0321 12:59:17.564891 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.0005826872,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.14530078,\n",
      " 'Loss/total_loss': 0.14588346,\n",
      " 'learning_rate': 0.079996705}\n",
      "INFO:tensorflow:Step 1300 per-step time 1.308s\n",
      "I0321 13:01:28.423535 4628336128 model_lib_v2.py:707] Step 1300 per-step time 1.308s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00052673527,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.14437406,\n",
      " 'Loss/total_loss': 0.1449008,\n",
      " 'learning_rate': 0.0799926}\n",
      "I0321 13:01:28.423813 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00052673527,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.14437406,\n",
      " 'Loss/total_loss': 0.1449008,\n",
      " 'learning_rate': 0.0799926}\n",
      "INFO:tensorflow:Step 1400 per-step time 1.314s\n",
      "I0321 13:03:39.788414 4628336128 model_lib_v2.py:707] Step 1400 per-step time 1.314s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0004526498,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.1434533,\n",
      " 'Loss/total_loss': 0.14390595,\n",
      " 'learning_rate': 0.07998685}\n",
      "I0321 13:03:39.788693 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.0004526498,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.1434533,\n",
      " 'Loss/total_loss': 0.14390595,\n",
      " 'learning_rate': 0.07998685}\n",
      "INFO:tensorflow:Step 1500 per-step time 1.319s\n",
      "I0321 13:05:51.715524 4628336128 model_lib_v2.py:707] Step 1500 per-step time 1.319s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00036025458,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.14253843,\n",
      " 'Loss/total_loss': 0.14289868,\n",
      " 'learning_rate': 0.07997945}\n",
      "I0321 13:05:51.715801 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00036025458,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.14253843,\n",
      " 'Loss/total_loss': 0.14289868,\n",
      " 'learning_rate': 0.07997945}\n",
      "INFO:tensorflow:Step 1600 per-step time 1.328s\n",
      "I0321 13:08:04.562970 4628336128 model_lib_v2.py:707] Step 1600 per-step time 1.328s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00032234495,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.14162944,\n",
      " 'Loss/total_loss': 0.14195178,\n",
      " 'learning_rate': 0.079970405}\n",
      "I0321 13:08:04.563251 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00032234495,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.14162944,\n",
      " 'Loss/total_loss': 0.14195178,\n",
      " 'learning_rate': 0.079970405}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step 1700 per-step time 1.335s\n",
      "I0321 13:10:18.073889 4628336128 model_lib_v2.py:707] Step 1700 per-step time 1.335s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00030623513,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.14072633,\n",
      " 'Loss/total_loss': 0.14103256,\n",
      " 'learning_rate': 0.07995972}\n",
      "I0321 13:10:18.074170 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00030623513,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.14072633,\n",
      " 'Loss/total_loss': 0.14103256,\n",
      " 'learning_rate': 0.07995972}\n",
      "INFO:tensorflow:Step 1800 per-step time 1.357s\n",
      "I0321 13:12:33.753960 4628336128 model_lib_v2.py:707] Step 1800 per-step time 1.357s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00035915826,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.1398291,\n",
      " 'Loss/total_loss': 0.14018826,\n",
      " 'learning_rate': 0.0799474}\n",
      "I0321 13:12:33.754245 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00035915826,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.1398291,\n",
      " 'Loss/total_loss': 0.14018826,\n",
      " 'learning_rate': 0.0799474}\n",
      "INFO:tensorflow:Step 1900 per-step time 1.353s\n",
      "I0321 13:14:49.050952 4628336128 model_lib_v2.py:707] Step 1900 per-step time 1.353s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0003132039,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.13893776,\n",
      " 'Loss/total_loss': 0.13925096,\n",
      " 'learning_rate': 0.07993342}\n",
      "I0321 13:14:49.051233 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.0003132039,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.13893776,\n",
      " 'Loss/total_loss': 0.13925096,\n",
      " 'learning_rate': 0.07993342}\n",
      "INFO:tensorflow:Step 2000 per-step time 1.424s\n",
      "I0321 13:17:11.433461 4628336128 model_lib_v2.py:707] Step 2000 per-step time 1.424s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00024588135,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.13805217,\n",
      " 'Loss/total_loss': 0.13829805,\n",
      " 'learning_rate': 0.07991781}\n",
      "I0321 13:17:11.433758 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00024588135,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.13805217,\n",
      " 'Loss/total_loss': 0.13829805,\n",
      " 'learning_rate': 0.07991781}\n",
      "INFO:tensorflow:Step 2100 per-step time 1.511s\n",
      "I0321 13:19:42.580187 4628336128 model_lib_v2.py:707] Step 2100 per-step time 1.511s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00023759356,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.13717248,\n",
      " 'Loss/total_loss': 0.13741007,\n",
      " 'learning_rate': 0.07990056}\n",
      "I0321 13:19:42.580499 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00023759356,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.13717248,\n",
      " 'Loss/total_loss': 0.13741007,\n",
      " 'learning_rate': 0.07990056}\n",
      "INFO:tensorflow:Step 2200 per-step time 1.561s\n",
      "I0321 13:22:18.657441 4628336128 model_lib_v2.py:707] Step 2200 per-step time 1.561s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00020963681,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.13629852,\n",
      " 'Loss/total_loss': 0.13650815,\n",
      " 'learning_rate': 0.07988167}\n",
      "I0321 13:22:18.657761 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00020963681,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.13629852,\n",
      " 'Loss/total_loss': 0.13650815,\n",
      " 'learning_rate': 0.07988167}\n",
      "INFO:tensorflow:Step 2300 per-step time 1.561s\n",
      "I0321 13:24:54.794913 4628336128 model_lib_v2.py:707] Step 2300 per-step time 1.561s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00020059585,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.13543032,\n",
      " 'Loss/total_loss': 0.13563092,\n",
      " 'learning_rate': 0.07986114}\n",
      "I0321 13:24:54.795236 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00020059585,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.13543032,\n",
      " 'Loss/total_loss': 0.13563092,\n",
      " 'learning_rate': 0.07986114}\n",
      "INFO:tensorflow:Step 2400 per-step time 1.552s\n",
      "I0321 13:27:29.992366 4628336128 model_lib_v2.py:707] Step 2400 per-step time 1.552s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00019179202,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.1345679,\n",
      " 'Loss/total_loss': 0.1347597,\n",
      " 'learning_rate': 0.07983897}\n",
      "I0321 13:27:29.992702 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00019179202,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.1345679,\n",
      " 'Loss/total_loss': 0.1347597,\n",
      " 'learning_rate': 0.07983897}\n",
      "INFO:tensorflow:Step 2500 per-step time 1.586s\n",
      "I0321 13:30:08.640951 4628336128 model_lib_v2.py:707] Step 2500 per-step time 1.586s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00017800549,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.13371117,\n",
      " 'Loss/total_loss': 0.13388918,\n",
      " 'learning_rate': 0.079815164}\n",
      "I0321 13:30:08.641382 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00017800549,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.13371117,\n",
      " 'Loss/total_loss': 0.13388918,\n",
      " 'learning_rate': 0.079815164}\n",
      "INFO:tensorflow:Step 2600 per-step time 1.627s\n",
      "I0321 13:32:51.322443 4628336128 model_lib_v2.py:707] Step 2600 per-step time 1.627s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00016733957,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.13286015,\n",
      " 'Loss/total_loss': 0.1330275,\n",
      " 'learning_rate': 0.07978972}\n",
      "I0321 13:32:51.322768 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00016733957,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.13286015,\n",
      " 'Loss/total_loss': 0.1330275,\n",
      " 'learning_rate': 0.07978972}\n",
      "INFO:tensorflow:Step 2700 per-step time 1.646s\n",
      "I0321 13:35:35.899868 4628336128 model_lib_v2.py:707] Step 2700 per-step time 1.646s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00017117939,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.13201487,\n",
      " 'Loss/total_loss': 0.13218606,\n",
      " 'learning_rate': 0.07976264}\n",
      "I0321 13:35:35.900191 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00017117939,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.13201487,\n",
      " 'Loss/total_loss': 0.13218606,\n",
      " 'learning_rate': 0.07976264}\n",
      "INFO:tensorflow:Step 2800 per-step time 1.708s\n",
      "I0321 13:38:26.746213 4628336128 model_lib_v2.py:707] Step 2800 per-step time 1.708s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00019313148,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.1311752,\n",
      " 'Loss/total_loss': 0.13136834,\n",
      " 'learning_rate': 0.07973392}\n",
      "I0321 13:38:26.746556 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00019313148,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.1311752,\n",
      " 'Loss/total_loss': 0.13136834,\n",
      " 'learning_rate': 0.07973392}\n",
      "INFO:tensorflow:Step 2900 per-step time 1.755s\n",
      "I0321 13:41:22.234308 4628336128 model_lib_v2.py:707] Step 2900 per-step time 1.755s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00014646999,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.1303412,\n",
      " 'Loss/total_loss': 0.13048767,\n",
      " 'learning_rate': 0.07970358}\n",
      "I0321 13:41:22.234660 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00014646999,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.1303412,\n",
      " 'Loss/total_loss': 0.13048767,\n",
      " 'learning_rate': 0.07970358}\n",
      "INFO:tensorflow:Step 3000 per-step time 1.774s\n",
      "I0321 13:44:19.586348 4628336128 model_lib_v2.py:707] Step 3000 per-step time 1.774s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00015217788,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.1295128,\n",
      " 'Loss/total_loss': 0.12966497,\n",
      " 'learning_rate': 0.0796716}\n",
      "I0321 13:44:19.586681 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00015217788,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.1295128,\n",
      " 'Loss/total_loss': 0.12966497,\n",
      " 'learning_rate': 0.0796716}\n",
      "INFO:tensorflow:Step 3100 per-step time 1.772s\n",
      "I0321 13:47:16.801235 4628336128 model_lib_v2.py:707] Step 3100 per-step time 1.772s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0001807595,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.12869,\n",
      " 'Loss/total_loss': 0.12887077,\n",
      " 'learning_rate': 0.07963799}\n",
      "I0321 13:47:16.801620 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.0001807595,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.12869,\n",
      " 'Loss/total_loss': 0.12887077,\n",
      " 'learning_rate': 0.07963799}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step 3200 per-step time 1.758s\n",
      "I0321 13:50:12.642971 4628336128 model_lib_v2.py:707] Step 3200 per-step time 1.758s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0001333377,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.1278728,\n",
      " 'Loss/total_loss': 0.12800613,\n",
      " 'learning_rate': 0.07960275}\n",
      "I0321 13:50:12.643305 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.0001333377,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.1278728,\n",
      " 'Loss/total_loss': 0.12800613,\n",
      " 'learning_rate': 0.07960275}\n",
      "INFO:tensorflow:Step 3300 per-step time 1.766s\n",
      "I0321 13:53:09.209317 4628336128 model_lib_v2.py:707] Step 3300 per-step time 1.766s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00013740658,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.12706114,\n",
      " 'Loss/total_loss': 0.12719855,\n",
      " 'learning_rate': 0.07956588}\n",
      "I0321 13:53:09.209671 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00013740658,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.12706114,\n",
      " 'Loss/total_loss': 0.12719855,\n",
      " 'learning_rate': 0.07956588}\n",
      "INFO:tensorflow:Step 3400 per-step time 1.757s\n",
      "I0321 13:56:04.881744 4628336128 model_lib_v2.py:707] Step 3400 per-step time 1.757s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00012210984,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.12625499,\n",
      " 'Loss/total_loss': 0.1263771,\n",
      " 'learning_rate': 0.079527386}\n",
      "I0321 13:56:04.882157 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00012210984,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.12625499,\n",
      " 'Loss/total_loss': 0.1263771,\n",
      " 'learning_rate': 0.079527386}\n",
      "INFO:tensorflow:Step 3500 per-step time 1.737s\n",
      "I0321 13:58:58.563644 4628336128 model_lib_v2.py:707] Step 3500 per-step time 1.737s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00013246541,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.12545435,\n",
      " 'Loss/total_loss': 0.12558682,\n",
      " 'learning_rate': 0.07948727}\n",
      "I0321 13:58:58.563971 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00013246541,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.12545435,\n",
      " 'Loss/total_loss': 0.12558682,\n",
      " 'learning_rate': 0.07948727}\n",
      "INFO:tensorflow:Step 3600 per-step time 1.747s\n",
      "I0321 14:01:53.245169 4628336128 model_lib_v2.py:707] Step 3600 per-step time 1.747s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.000112043825,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.12465918,\n",
      " 'Loss/total_loss': 0.12477122,\n",
      " 'learning_rate': 0.079445526}\n",
      "I0321 14:01:53.245555 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.000112043825,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.12465918,\n",
      " 'Loss/total_loss': 0.12477122,\n",
      " 'learning_rate': 0.079445526}\n",
      "INFO:tensorflow:Step 3700 per-step time 1.745s\n",
      "I0321 14:04:47.760982 4628336128 model_lib_v2.py:707] Step 3700 per-step time 1.745s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00011275541,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.123869464,\n",
      " 'Loss/total_loss': 0.12398222,\n",
      " 'learning_rate': 0.07940216}\n",
      "I0321 14:04:47.761312 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00011275541,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.123869464,\n",
      " 'Loss/total_loss': 0.12398222,\n",
      " 'learning_rate': 0.07940216}\n",
      "INFO:tensorflow:Step 3800 per-step time 1.747s\n",
      "I0321 14:07:42.425156 4628336128 model_lib_v2.py:707] Step 3800 per-step time 1.747s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00010592182,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.123085186,\n",
      " 'Loss/total_loss': 0.12319111,\n",
      " 'learning_rate': 0.079357184}\n",
      "I0321 14:07:42.425493 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00010592182,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.123085186,\n",
      " 'Loss/total_loss': 0.12319111,\n",
      " 'learning_rate': 0.079357184}\n",
      "INFO:tensorflow:Step 3900 per-step time 1.745s\n",
      "I0321 14:10:36.886494 4628336128 model_lib_v2.py:707] Step 3900 per-step time 1.745s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00012971634,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.12230634,\n",
      " 'Loss/total_loss': 0.122436054,\n",
      " 'learning_rate': 0.07931058}\n",
      "I0321 14:10:36.886837 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00012971634,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.12230634,\n",
      " 'Loss/total_loss': 0.122436054,\n",
      " 'learning_rate': 0.07931058}\n",
      "INFO:tensorflow:Step 4000 per-step time 1.761s\n",
      "I0321 14:13:32.954824 4628336128 model_lib_v2.py:707] Step 4000 per-step time 1.761s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.00010575863,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.121532865,\n",
      " 'Loss/total_loss': 0.121638626,\n",
      " 'learning_rate': 0.07926236}\n",
      "I0321 14:13:32.955163 4628336128 model_lib_v2.py:708] {'Loss/classification_loss': 0.00010575863,\n",
      " 'Loss/localization_loss': 0.0,\n",
      " 'Loss/regularization_loss': 0.121532865,\n",
      " 'Loss/total_loss': 0.121638626,\n",
      " 'learning_rate': 0.07926236}\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python TF_Sign_Detection/models/research/object_detection/model_main_tf2.py --model_dir=TF_Sign_Detection/workspace/models/my_ssd_mobnet --pipeline_config_path=TF_Sign_Detection/workspace/models/my_ssd_mobnet/pipeline.config --checkpoint_dir=TF_Sign_Detection/workspace/models/my_ssd_mobnet\n"
     ]
    }
   ],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "W0322 15:20:28.811857 4589100544 model_lib_v2.py:1090] Forced number of epochs for all eval validations to be 1.\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "I0322 15:20:28.812102 4589100544 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0322 15:20:28.812208 4589100544 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "I0322 15:20:28.812309 4589100544 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "W0322 15:20:28.812440 4589100544 model_lib_v2.py:1111] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "2022-03-22 15:20:28.823399: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO:tensorflow:Reading unweighted datasets: ['TF_Sign_Detection/workspace/annotations/test.record']\n",
      "I0322 15:20:28.897598 4589100544 dataset_builder.py:163] Reading unweighted datasets: ['TF_Sign_Detection/workspace/annotations/test.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['TF_Sign_Detection/workspace/annotations/test.record']\n",
      "I0322 15:20:28.902017 4589100544 dataset_builder.py:80] Reading record datasets for input file: ['TF_Sign_Detection/workspace/annotations/test.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0322 15:20:28.902251 4589100544 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0322 15:20:28.902409 4589100544 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0322 15:20:28.913592 4589100544 deprecation.py:343] From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0322 15:20:29.113023 4589100544 deprecation.py:343] From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0322 15:20:42.194051 4589100544 deprecation.py:343] From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0322 15:20:48.722954 4589100544 deprecation.py:343] From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Waiting for new checkpoint at TF_Sign_Detection/workspace/models/my_ssd_mobnet\n",
      "I0322 15:20:51.645668 4589100544 checkpoint_utils.py:136] Waiting for new checkpoint at TF_Sign_Detection/workspace/models/my_ssd_mobnet\n",
      "INFO:tensorflow:Found new checkpoint at TF_Sign_Detection/workspace/models/my_ssd_mobnet/ckpt-5\n",
      "I0322 15:20:51.646341 4589100544 checkpoint_utils.py:145] Found new checkpoint at TF_Sign_Detection/workspace/models/my_ssd_mobnet/ckpt-5\n",
      "/Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "WARNING:tensorflow:From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0322 16:45:01.966742 4589100544 deprecation.py:343] From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Finished eval step 0\n",
      "I0322 16:45:01.974869 4589100544 model_lib_v2.py:966] Finished eval step 0\n",
      "WARNING:tensorflow:From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "W0322 16:45:02.315141 4589100544 deprecation.py:343] From /Users/wala/Desktop/Kaggle_compet/Traffic_Sign_Detection/TFSD/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished eval step 100\n",
      "I0322 16:45:25.759294 4589100544 model_lib_v2.py:966] Finished eval step 100\n",
      "INFO:tensorflow:Finished eval step 200\n",
      "I0322 16:46:10.986215 4589100544 model_lib_v2.py:966] Finished eval step 200\n",
      "INFO:tensorflow:Finished eval step 300\n",
      "I0322 16:46:33.773626 4589100544 model_lib_v2.py:966] Finished eval step 300\n",
      "INFO:tensorflow:Finished eval step 400\n",
      "I0322 16:47:11.665417 4589100544 model_lib_v2.py:966] Finished eval step 400\n",
      "INFO:tensorflow:Finished eval step 500\n",
      "I0322 16:47:33.952613 4589100544 model_lib_v2.py:966] Finished eval step 500\n",
      "INFO:tensorflow:Finished eval step 600\n",
      "I0322 17:42:36.504214 4589100544 model_lib_v2.py:966] Finished eval step 600\n",
      "INFO:tensorflow:Finished eval step 700\n",
      "I0322 17:43:01.861690 4589100544 model_lib_v2.py:966] Finished eval step 700\n",
      "INFO:tensorflow:Finished eval step 800\n",
      "I0322 18:16:57.820321 4589100544 model_lib_v2.py:966] Finished eval step 800\n",
      "INFO:tensorflow:Finished eval step 900\n",
      "I0322 19:38:03.111422 4589100544 model_lib_v2.py:966] Finished eval step 900\n",
      "INFO:tensorflow:Finished eval step 1000\n",
      "I0322 19:38:14.554764 4589100544 model_lib_v2.py:966] Finished eval step 1000\n",
      "INFO:tensorflow:Finished eval step 1100\n",
      "I0322 20:04:54.561179 4589100544 model_lib_v2.py:966] Finished eval step 1100\n",
      "INFO:tensorflow:Finished eval step 1200\n",
      "I0322 20:05:05.213352 4589100544 model_lib_v2.py:966] Finished eval step 1200\n",
      "INFO:tensorflow:Finished eval step 1300\n",
      "I0322 20:05:16.037493 4589100544 model_lib_v2.py:966] Finished eval step 1300\n",
      "INFO:tensorflow:Finished eval step 1400\n",
      "I0322 20:05:30.101009 4589100544 model_lib_v2.py:966] Finished eval step 1400\n",
      "INFO:tensorflow:Finished eval step 1500\n",
      "I0322 20:05:40.751405 4589100544 model_lib_v2.py:966] Finished eval step 1500\n",
      "INFO:tensorflow:Finished eval step 1600\n",
      "I0322 20:05:51.676303 4589100544 model_lib_v2.py:966] Finished eval step 1600\n",
      "INFO:tensorflow:Finished eval step 1700\n",
      "I0322 20:06:04.172583 4589100544 model_lib_v2.py:966] Finished eval step 1700\n",
      "INFO:tensorflow:Finished eval step 1800\n",
      "I0322 20:06:28.033747 4589100544 model_lib_v2.py:966] Finished eval step 1800\n",
      "INFO:tensorflow:Finished eval step 1900\n",
      "I0322 20:06:53.228874 4589100544 model_lib_v2.py:966] Finished eval step 1900\n",
      "INFO:tensorflow:Finished eval step 2000\n",
      "I0322 20:07:02.922305 4589100544 model_lib_v2.py:966] Finished eval step 2000\n",
      "INFO:tensorflow:Finished eval step 2100\n",
      "I0322 20:07:14.139611 4589100544 model_lib_v2.py:966] Finished eval step 2100\n",
      "INFO:tensorflow:Finished eval step 2200\n",
      "I0322 20:34:21.107831 4589100544 model_lib_v2.py:966] Finished eval step 2200\n",
      "INFO:tensorflow:Finished eval step 2300\n",
      "I0322 20:34:40.444461 4589100544 model_lib_v2.py:966] Finished eval step 2300\n",
      "INFO:tensorflow:Finished eval step 2400\n",
      "I0322 20:34:50.159604 4589100544 model_lib_v2.py:966] Finished eval step 2400\n",
      "INFO:tensorflow:Finished eval step 2500\n",
      "I0322 20:35:00.033428 4589100544 model_lib_v2.py:966] Finished eval step 2500\n",
      "INFO:tensorflow:Finished eval step 2600\n",
      "I0322 20:40:07.322849 4589100544 model_lib_v2.py:966] Finished eval step 2600\n",
      "INFO:tensorflow:Finished eval step 2700\n",
      "I0322 20:40:27.085403 4589100544 model_lib_v2.py:966] Finished eval step 2700\n",
      "INFO:tensorflow:Finished eval step 2800\n",
      "I0322 20:40:36.611423 4589100544 model_lib_v2.py:966] Finished eval step 2800\n",
      "INFO:tensorflow:Finished eval step 2900\n",
      "I0322 20:40:46.989855 4589100544 model_lib_v2.py:966] Finished eval step 2900\n",
      "INFO:tensorflow:Finished eval step 3000\n",
      "I0322 20:40:57.203499 4589100544 model_lib_v2.py:966] Finished eval step 3000\n",
      "INFO:tensorflow:Finished eval step 3100\n",
      "I0322 20:41:08.211600 4589100544 model_lib_v2.py:966] Finished eval step 3100\n",
      "INFO:tensorflow:Finished eval step 3200\n",
      "I0322 20:41:19.071475 4589100544 model_lib_v2.py:966] Finished eval step 3200\n",
      "INFO:tensorflow:Finished eval step 3300\n",
      "I0322 20:41:30.051486 4589100544 model_lib_v2.py:966] Finished eval step 3300\n",
      "INFO:tensorflow:Finished eval step 3400\n",
      "I0322 20:41:41.918945 4589100544 model_lib_v2.py:966] Finished eval step 3400\n",
      "INFO:tensorflow:Finished eval step 3500\n",
      "I0322 20:41:54.658490 4589100544 model_lib_v2.py:966] Finished eval step 3500\n",
      "INFO:tensorflow:Finished eval step 3600\n",
      "I0322 20:42:06.613700 4589100544 model_lib_v2.py:966] Finished eval step 3600\n",
      "INFO:tensorflow:Finished eval step 3700\n",
      "I0322 20:42:19.534458 4589100544 model_lib_v2.py:966] Finished eval step 3700\n",
      "INFO:tensorflow:Finished eval step 3800\n",
      "I0322 20:42:32.081883 4589100544 model_lib_v2.py:966] Finished eval step 3800\n",
      "INFO:tensorflow:Finished eval step 3900\n",
      "I0322 20:42:44.609433 4589100544 model_lib_v2.py:966] Finished eval step 3900\n",
      "INFO:tensorflow:Finished eval step 4000\n",
      "I0322 20:42:56.659434 4589100544 model_lib_v2.py:966] Finished eval step 4000\n",
      "INFO:tensorflow:Finished eval step 4100\n",
      "I0322 20:43:09.050118 4589100544 model_lib_v2.py:966] Finished eval step 4100\n",
      "INFO:tensorflow:Finished eval step 4200\n",
      "I0322 20:43:21.740441 4589100544 model_lib_v2.py:966] Finished eval step 4200\n",
      "INFO:tensorflow:Finished eval step 4300\n",
      "I0322 20:43:34.239955 4589100544 model_lib_v2.py:966] Finished eval step 4300\n",
      "INFO:tensorflow:Finished eval step 4400\n",
      "I0322 20:43:47.326785 4589100544 model_lib_v2.py:966] Finished eval step 4400\n",
      "INFO:tensorflow:Finished eval step 4500\n",
      "I0322 20:44:00.549417 4589100544 model_lib_v2.py:966] Finished eval step 4500\n",
      "INFO:tensorflow:Finished eval step 4600\n",
      "I0322 20:44:13.543107 4589100544 model_lib_v2.py:966] Finished eval step 4600\n",
      "INFO:tensorflow:Finished eval step 4700\n",
      "I0322 20:44:26.430763 4589100544 model_lib_v2.py:966] Finished eval step 4700\n",
      "INFO:tensorflow:Finished eval step 4800\n",
      "I0322 20:44:39.330403 4589100544 model_lib_v2.py:966] Finished eval step 4800\n",
      "INFO:tensorflow:Finished eval step 4900\n",
      "I0322 20:44:52.159439 4589100544 model_lib_v2.py:966] Finished eval step 4900\n",
      "INFO:tensorflow:Finished eval step 5000\n",
      "I0322 20:45:05.222877 4589100544 model_lib_v2.py:966] Finished eval step 5000\n",
      "INFO:tensorflow:Finished eval step 5100\n",
      "I0322 20:45:17.883156 4589100544 model_lib_v2.py:966] Finished eval step 5100\n",
      "INFO:tensorflow:Finished eval step 5200\n",
      "I0322 20:45:30.703497 4589100544 model_lib_v2.py:966] Finished eval step 5200\n",
      "INFO:tensorflow:Finished eval step 5300\n",
      "I0322 20:45:43.568966 4589100544 model_lib_v2.py:966] Finished eval step 5300\n",
      "INFO:tensorflow:Finished eval step 5400\n",
      "I0322 20:45:56.403642 4589100544 model_lib_v2.py:966] Finished eval step 5400\n",
      "INFO:tensorflow:Finished eval step 5500\n",
      "I0322 20:46:09.341850 4589100544 model_lib_v2.py:966] Finished eval step 5500\n",
      "INFO:tensorflow:Finished eval step 5600\n",
      "I0322 20:46:22.195998 4589100544 model_lib_v2.py:966] Finished eval step 5600\n",
      "INFO:tensorflow:Finished eval step 5700\n",
      "I0322 20:46:35.214553 4589100544 model_lib_v2.py:966] Finished eval step 5700\n",
      "INFO:tensorflow:Finished eval step 5800\n",
      "I0322 20:46:48.094051 4589100544 model_lib_v2.py:966] Finished eval step 5800\n",
      "INFO:tensorflow:Finished eval step 5900\n",
      "I0322 20:47:01.152805 4589100544 model_lib_v2.py:966] Finished eval step 5900\n",
      "INFO:tensorflow:Finished eval step 6000\n",
      "I0322 20:47:14.029309 4589100544 model_lib_v2.py:966] Finished eval step 6000\n",
      "INFO:tensorflow:Finished eval step 6100\n",
      "I0322 20:47:27.088368 4589100544 model_lib_v2.py:966] Finished eval step 6100\n",
      "INFO:tensorflow:Finished eval step 6200\n",
      "I0322 20:47:40.211697 4589100544 model_lib_v2.py:966] Finished eval step 6200\n",
      "INFO:tensorflow:Finished eval step 6300\n",
      "I0322 20:47:53.374130 4589100544 model_lib_v2.py:966] Finished eval step 6300\n",
      "INFO:tensorflow:Finished eval step 6400\n",
      "I0322 20:48:06.503756 4589100544 model_lib_v2.py:966] Finished eval step 6400\n",
      "INFO:tensorflow:Finished eval step 6500\n",
      "I0322 20:48:19.465822 4589100544 model_lib_v2.py:966] Finished eval step 6500\n",
      "INFO:tensorflow:Finished eval step 6600\n",
      "I0322 20:48:32.374565 4589100544 model_lib_v2.py:966] Finished eval step 6600\n",
      "INFO:tensorflow:Finished eval step 6700\n",
      "I0322 20:48:45.354639 4589100544 model_lib_v2.py:966] Finished eval step 6700\n",
      "INFO:tensorflow:Finished eval step 6800\n",
      "I0322 20:48:59.034878 4589100544 model_lib_v2.py:966] Finished eval step 6800\n",
      "INFO:tensorflow:Finished eval step 6900\n",
      "I0322 20:49:11.862724 4589100544 model_lib_v2.py:966] Finished eval step 6900\n",
      "INFO:tensorflow:Finished eval step 7000\n",
      "I0322 20:49:24.624893 4589100544 model_lib_v2.py:966] Finished eval step 7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished eval step 7100\n",
      "I0322 20:49:37.428842 4589100544 model_lib_v2.py:966] Finished eval step 7100\n",
      "INFO:tensorflow:Finished eval step 7200\n",
      "I0322 20:49:50.481313 4589100544 model_lib_v2.py:966] Finished eval step 7200\n",
      "INFO:tensorflow:Finished eval step 7300\n",
      "I0322 20:50:03.451206 4589100544 model_lib_v2.py:966] Finished eval step 7300\n",
      "INFO:tensorflow:Finished eval step 7400\n",
      "I0322 20:50:16.331636 4589100544 model_lib_v2.py:966] Finished eval step 7400\n",
      "INFO:tensorflow:Finished eval step 7500\n",
      "I0322 20:50:29.152631 4589100544 model_lib_v2.py:966] Finished eval step 7500\n",
      "INFO:tensorflow:Finished eval step 7600\n",
      "I0322 20:50:42.139630 4589100544 model_lib_v2.py:966] Finished eval step 7600\n",
      "INFO:tensorflow:Finished eval step 7700\n",
      "I0322 20:50:54.934458 4589100544 model_lib_v2.py:966] Finished eval step 7700\n",
      "INFO:tensorflow:Finished eval step 7800\n",
      "I0322 20:51:07.745824 4589100544 model_lib_v2.py:966] Finished eval step 7800\n",
      "INFO:tensorflow:Finished eval step 7900\n",
      "I0322 20:51:20.714042 4589100544 model_lib_v2.py:966] Finished eval step 7900\n",
      "INFO:tensorflow:Finished eval step 8000\n",
      "I0322 20:51:33.455430 4589100544 model_lib_v2.py:966] Finished eval step 8000\n",
      "INFO:tensorflow:Finished eval step 8100\n",
      "I0322 20:51:46.384576 4589100544 model_lib_v2.py:966] Finished eval step 8100\n",
      "INFO:tensorflow:Finished eval step 8200\n",
      "I0322 20:51:59.559272 4589100544 model_lib_v2.py:966] Finished eval step 8200\n",
      "INFO:tensorflow:Finished eval step 8300\n",
      "I0322 20:52:13.033786 4589100544 model_lib_v2.py:966] Finished eval step 8300\n",
      "INFO:tensorflow:Finished eval step 8400\n",
      "I0322 20:52:26.603674 4589100544 model_lib_v2.py:966] Finished eval step 8400\n",
      "INFO:tensorflow:Finished eval step 8500\n",
      "I0322 20:52:40.004207 4589100544 model_lib_v2.py:966] Finished eval step 8500\n",
      "INFO:tensorflow:Finished eval step 8600\n",
      "I0322 20:52:53.881795 4589100544 model_lib_v2.py:966] Finished eval step 8600\n",
      "INFO:tensorflow:Finished eval step 8700\n",
      "I0322 20:53:07.691284 4589100544 model_lib_v2.py:966] Finished eval step 8700\n",
      "INFO:tensorflow:Finished eval step 8800\n",
      "I0322 20:53:21.671606 4589100544 model_lib_v2.py:966] Finished eval step 8800\n",
      "INFO:tensorflow:Finished eval step 8900\n",
      "I0322 20:53:36.090756 4589100544 model_lib_v2.py:966] Finished eval step 8900\n",
      "INFO:tensorflow:Finished eval step 9000\n",
      "I0322 20:53:50.256207 4589100544 model_lib_v2.py:966] Finished eval step 9000\n",
      "INFO:tensorflow:Finished eval step 9100\n",
      "I0322 20:54:05.198444 4589100544 model_lib_v2.py:966] Finished eval step 9100\n",
      "INFO:tensorflow:Finished eval step 9200\n",
      "I0322 20:54:20.415920 4589100544 model_lib_v2.py:966] Finished eval step 9200\n",
      "INFO:tensorflow:Finished eval step 9300\n",
      "I0322 20:54:34.590449 4589100544 model_lib_v2.py:966] Finished eval step 9300\n",
      "INFO:tensorflow:Finished eval step 9400\n",
      "I0322 20:54:50.186597 4589100544 model_lib_v2.py:966] Finished eval step 9400\n",
      "INFO:tensorflow:Finished eval step 9500\n",
      "I0322 20:55:06.181361 4589100544 model_lib_v2.py:966] Finished eval step 9500\n",
      "INFO:tensorflow:Finished eval step 9600\n",
      "I0322 20:55:22.440192 4589100544 model_lib_v2.py:966] Finished eval step 9600\n",
      "INFO:tensorflow:Finished eval step 9700\n",
      "I0322 20:55:38.830683 4589100544 model_lib_v2.py:966] Finished eval step 9700\n",
      "INFO:tensorflow:Finished eval step 9800\n",
      "I0322 20:55:55.614766 4589100544 model_lib_v2.py:966] Finished eval step 9800\n",
      "INFO:tensorflow:Finished eval step 9900\n",
      "I0322 20:56:12.867465 4589100544 model_lib_v2.py:966] Finished eval step 9900\n",
      "INFO:tensorflow:Finished eval step 10000\n",
      "I0322 20:56:30.127140 4589100544 model_lib_v2.py:966] Finished eval step 10000\n",
      "INFO:tensorflow:Finished eval step 10100\n",
      "I0322 20:56:47.527962 4589100544 model_lib_v2.py:966] Finished eval step 10100\n",
      "INFO:tensorflow:Finished eval step 10200\n",
      "I0322 20:57:05.964790 4589100544 model_lib_v2.py:966] Finished eval step 10200\n",
      "INFO:tensorflow:Finished eval step 10300\n",
      "I0322 20:57:24.320040 4589100544 model_lib_v2.py:966] Finished eval step 10300\n",
      "INFO:tensorflow:Finished eval step 10400\n",
      "I0322 20:57:42.715574 4589100544 model_lib_v2.py:966] Finished eval step 10400\n",
      "INFO:tensorflow:Finished eval step 10500\n",
      "I0322 20:58:01.416282 4589100544 model_lib_v2.py:966] Finished eval step 10500\n",
      "INFO:tensorflow:Finished eval step 10600\n",
      "I0322 20:58:20.350461 4589100544 model_lib_v2.py:966] Finished eval step 10600\n",
      "INFO:tensorflow:Finished eval step 10700\n",
      "I0322 20:58:39.426868 4589100544 model_lib_v2.py:966] Finished eval step 10700\n",
      "INFO:tensorflow:Finished eval step 10800\n",
      "I0322 20:58:58.465750 4589100544 model_lib_v2.py:966] Finished eval step 10800\n",
      "INFO:tensorflow:Finished eval step 10900\n",
      "I0322 20:59:17.637773 4589100544 model_lib_v2.py:966] Finished eval step 10900\n",
      "INFO:tensorflow:Finished eval step 11000\n",
      "I0322 20:59:37.067143 4589100544 model_lib_v2.py:966] Finished eval step 11000\n",
      "INFO:tensorflow:Finished eval step 11100\n",
      "I0322 20:59:56.430433 4589100544 model_lib_v2.py:966] Finished eval step 11100\n",
      "INFO:tensorflow:Finished eval step 11200\n",
      "I0322 21:00:15.412572 4589100544 model_lib_v2.py:966] Finished eval step 11200\n",
      "INFO:tensorflow:Finished eval step 11300\n",
      "I0322 21:00:34.233530 4589100544 model_lib_v2.py:966] Finished eval step 11300\n",
      "INFO:tensorflow:Finished eval step 11400\n",
      "I0322 21:00:53.101254 4589100544 model_lib_v2.py:966] Finished eval step 11400\n",
      "INFO:tensorflow:Finished eval step 11500\n",
      "I0322 21:01:11.822502 4589100544 model_lib_v2.py:966] Finished eval step 11500\n",
      "INFO:tensorflow:Finished eval step 11600\n",
      "I0322 21:01:33.147876 4589100544 model_lib_v2.py:966] Finished eval step 11600\n",
      "INFO:tensorflow:Finished eval step 11700\n",
      "I0322 21:01:52.276068 4589100544 model_lib_v2.py:966] Finished eval step 11700\n",
      "INFO:tensorflow:Finished eval step 11800\n",
      "I0322 21:02:11.309344 4589100544 model_lib_v2.py:966] Finished eval step 11800\n",
      "INFO:tensorflow:Finished eval step 11900\n",
      "I0322 21:02:29.276145 4589100544 model_lib_v2.py:966] Finished eval step 11900\n",
      "INFO:tensorflow:Finished eval step 12000\n",
      "I0322 21:02:46.929332 4589100544 model_lib_v2.py:966] Finished eval step 12000\n",
      "INFO:tensorflow:Finished eval step 12100\n",
      "I0322 21:03:04.707090 4589100544 model_lib_v2.py:966] Finished eval step 12100\n",
      "INFO:tensorflow:Finished eval step 12200\n",
      "I0322 21:03:22.240266 4589100544 model_lib_v2.py:966] Finished eval step 12200\n",
      "INFO:tensorflow:Finished eval step 12300\n",
      "I0322 21:03:39.411038 4589100544 model_lib_v2.py:966] Finished eval step 12300\n",
      "INFO:tensorflow:Finished eval step 12400\n",
      "I0322 21:03:56.587166 4589100544 model_lib_v2.py:966] Finished eval step 12400\n",
      "INFO:tensorflow:Finished eval step 12500\n",
      "I0322 21:04:13.457937 4589100544 model_lib_v2.py:966] Finished eval step 12500\n",
      "INFO:tensorflow:Finished eval step 12600\n",
      "I0322 21:04:30.583766 4589100544 model_lib_v2.py:966] Finished eval step 12600\n",
      "INFO:tensorflow:Performing evaluation on 12630 images.\n",
      "I0322 21:04:35.442594 4589100544 coco_evaluation.py:293] Performing evaluation on 12630 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I0322 21:04:35.457848 4589100544 coco_tools.py:116] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=1.04s)\n",
      "I0322 21:04:36.501934 4589100544 coco_tools.py:138] DONE (t=1.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=273.88s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=119.88s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Eval metrics at step 4000\n",
      "I0322 21:11:24.233849 4589100544 model_lib_v2.py:1015] Eval metrics at step 4000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: -1.000000\n",
      "I0322 21:11:24.345637 4589100544 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: -1.000000\n",
      "I0322 21:11:24.347241 4589100544 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: -1.000000\n",
      "I0322 21:11:24.348316 4589100544 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
      "I0322 21:11:24.349147 4589100544 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): -1.000000\n",
      "I0322 21:11:24.349868 4589100544 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): -1.000000\n",
      "I0322 21:11:24.350634 4589100544 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: -1.000000\n",
      "I0322 21:11:24.352467 4589100544 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: -1.000000\n",
      "I0322 21:11:24.353189 4589100544 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: -1.000000\n",
      "I0322 21:11:24.353821 4589100544 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
      "I0322 21:11:24.354448 4589100544 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): -1.000000\n",
      "I0322 21:11:24.355083 4589100544 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): -1.000000\n",
      "I0322 21:11:24.355795 4589100544 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): -1.000000\n",
      "INFO:tensorflow:\t+ Loss/localization_loss: 0.000000\n",
      "I0322 21:11:24.356360 4589100544 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.000000\n",
      "INFO:tensorflow:\t+ Loss/classification_loss: 0.000027\n",
      "I0322 21:11:24.358258 4589100544 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.000027\n",
      "INFO:tensorflow:\t+ Loss/regularization_loss: 0.121525\n",
      "I0322 21:11:24.358896 4589100544 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.121525\n",
      "INFO:tensorflow:\t+ Loss/total_loss: 0.121552\n",
      "I0322 21:11:24.359537 4589100544 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.121552\n",
      "INFO:tensorflow:Waiting for new checkpoint at TF_Sign_Detection/workspace/models/my_ssd_mobnet\n",
      "I0322 21:11:27.442604 4589100544 checkpoint_utils.py:136] Waiting for new checkpoint at TF_Sign_Detection/workspace/models/my_ssd_mobnet\n",
      "INFO:tensorflow:Timed-out waiting for a checkpoint.\n",
      "I0322 22:11:26.901114 4589100544 checkpoint_utils.py:199] Timed-out waiting for a checkpoint.\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Load Train Model From Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-5')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Detect from an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])\n",
    "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'Train/2', '00002_00002_00011.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=5,\n",
    "            min_score_thresh=.8,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections['detection_classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "TFSD",
   "language": "python",
   "name": "tfsd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
